{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU via MPS (Apple Silicon)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsc/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Using GPU via CUDA:', torch.cuda.get_device_name(0))\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print('Using GPU via MPS (Apple Silicon)')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Using CPU')\n",
    "\n",
    "# Use device like this:\n",
    "# model.to(device)\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# Load miditok tokenizer\n",
    "from miditok import REMI, TokenizerConfig, TokSequence\n",
    "from miditoolkit import MidiFile, Instrument, Note\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dsc/lib/python3.9/site-packages/miditok/tokenizations/remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = REMI.from_pretrained(\"tokenizer.json\")\n",
    "\n",
    "# ----- Dataset -----\n",
    "class PairedMIDIDataset(Dataset):\n",
    "    def __init__(self, right_dir: Path, left_dir: Path, max_len=1024):\n",
    "        self.right_files = sorted(right_dir.glob(\"*.json\"))\n",
    "        self.left_files = sorted(left_dir.glob(\"*.json\"))\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.right_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(self.right_files[idx]) as f:\n",
    "            right = json.load(f)[:self.max_len]\n",
    "        with open(self.left_files[idx]) as f:\n",
    "            left = json.load(f)[:self.max_len]\n",
    "\n",
    "        return torch.tensor(right), torch.tensor(left)\n",
    "\n",
    "# ----- Collate function -----\n",
    "def collate_fn(batch):\n",
    "    right_batch, left_batch = zip(*batch)\n",
    "    #right_batch = [torch.tensor(seq, dtype=torch.long) for seq in right_batch]\n",
    "    #left_batch = [torch.tensor(seq, dtype=torch.long) for seq in left_batch]\n",
    "    right_batch = [\n",
    "        seq.clone().detach() if isinstance(seq, torch.Tensor) else torch.tensor(seq, dtype=torch.long)\n",
    "        for seq in right_batch\n",
    "    ]\n",
    "    left_batch = [\n",
    "        seq.clone().detach() if isinstance(seq, torch.Tensor) else torch.tensor(seq, dtype=torch.long)\n",
    "        for seq in left_batch\n",
    "    ]\n",
    "\n",
    "    pad_token_id = tokenizer[\"PAD_None\"]  # Use string-based access here\n",
    "    right_padded = nn.utils.rnn.pad_sequence(right_batch, batch_first=True, padding_value=pad_token_id)\n",
    "    left_padded = nn.utils.rnn.pad_sequence(left_batch, batch_first=True, padding_value=pad_token_id)\n",
    "\n",
    "    return right_padded, left_padded\n",
    "\n",
    "\n",
    "\n",
    "# ----- Dataloader -----\n",
    "right_json_dir = Path(\"tokenized_json/right_hand\")\n",
    "left_json_dir = Path(\"tokenized_json/left_hand\")\n",
    "\n",
    "dataset = PairedMIDIDataset(right_json_dir, left_json_dir)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# ----- Model: Simple Transformer -----\n",
    "class MusicTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=256, n_heads=4, n_layers=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_dim, nhead=n_heads)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=emb_dim, nhead=n_heads)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=n_layers)\n",
    "        self.fc_out = nn.Linear(emb_dim, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = self.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
    "        tgt_mask = self.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
    "\n",
    "        src_emb = self.embedding(src)\n",
    "        tgt_emb = self.embedding(tgt)\n",
    "        memory = self.encoder(src_emb.transpose(0, 1), src_mask)\n",
    "        out = self.decoder(tgt_emb.transpose(0, 1), memory, tgt_mask)\n",
    "        logits = self.fc_out(out.transpose(0, 1))\n",
    "        return logits\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        return torch.triu(torch.full((sz, sz), float('-inf')), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max token ID in dataset: 897\n",
      "Vocab size from tokenizer: 898\n",
      "Num valid token IDs: 249\n"
     ]
    }
   ],
   "source": [
    "all_ids = []\n",
    "for right, left in dataloader.dataset:\n",
    "    all_ids.extend(right)\n",
    "    all_ids.extend(left)\n",
    "\n",
    "print(f\"Max token ID in dataset: {max(all_ids)}\")\n",
    "print(f\"Vocab size from tokenizer: {len(tokenizer)}\")\n",
    "\n",
    "valid_token_id_set = set(t.item() for t in all_ids)\n",
    "valid_token_ids = torch.tensor(list(valid_token_id_set), dtype=torch.long, device=device)\n",
    "\n",
    "print(f\"Num valid token IDs: {len(valid_token_id_set)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 1.9416\n",
      "Loss improved from inf to 1.9416. Saving model...\n",
      "Epoch 2 - Loss: 1.3074\n",
      "Loss improved from 1.9416 to 1.3074. Saving model...\n",
      "Epoch 3 - Loss: 1.1642\n",
      "Loss improved from 1.3074 to 1.1642. Saving model...\n",
      "Epoch 4 - Loss: 1.0857\n",
      "Loss improved from 1.1642 to 1.0857. Saving model...\n",
      "Epoch 5 - Loss: 1.0299\n",
      "Loss improved from 1.0857 to 1.0299. Saving model...\n",
      "Epoch 6 - Loss: 0.9814\n",
      "Loss improved from 1.0299 to 0.9814. Saving model...\n",
      "Epoch 7 - Loss: 0.9515\n",
      "Loss improved from 0.9814 to 0.9515. Saving model...\n",
      "Epoch 8 - Loss: 0.9222\n",
      "Loss improved from 0.9515 to 0.9222. Saving model...\n",
      "Epoch 9 - Loss: 0.9022\n",
      "Loss improved from 0.9222 to 0.9022. Saving model...\n",
      "Epoch 10 - Loss: 0.8865\n",
      "Loss improved from 0.9022 to 0.8865. Saving model...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = len(valid_token_id_set)\n",
    "model = MusicTransformer(vocab_size=vocab_size)\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "pad_token = tokenizer.vocab.get(\"PAD_None\", -100)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_token)\n",
    "\n",
    "best_loss = float(\"inf\")  # Initialize best loss to very large value\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for src, tgt in dataloader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt[:, :-1])  # teacher forcing\n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), tgt[:, 1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Save the model if there is significant improvement\n",
    "    if avg_loss < best_loss:\n",
    "        print(f\"Loss improved from {best_loss:.4f} to {avg_loss:.4f}. Saving model...\")\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "\n",
    "torch.save(model.state_dict(), \"music_transformer_weights.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"music_transformer_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditoolkit import MidiFile, Instrument, Note\n",
    "\n",
    "def score_to_midi(score_tick):\n",
    "    midi = MidiFile()\n",
    "\n",
    "    # Correctly access instruments/tracks from ScoreTick\n",
    "    try:\n",
    "        for track in score_tick.tracks:  # ← this is the fix\n",
    "            midi_instr = Instrument(\n",
    "                program=track.program,\n",
    "                is_drum=track.is_drum,\n",
    "                name=track.name\n",
    "            )\n",
    "            for note in track.notes:\n",
    "                midi_instr.notes.append(Note(\n",
    "                    pitch=note.pitch,\n",
    "                    start=note.start,\n",
    "                    end=note.end,\n",
    "                    velocity=note.velocity\n",
    "                ))\n",
    "            midi.instruments.append(midi_instr)\n",
    "    except AttributeError as e:\n",
    "        raise ValueError(\"Provided object does not contain valid MIDI track info\") from e\n",
    "\n",
    "    return midi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditoolkit import MidiFile, Instrument\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def generate_left_hand_and_save_midi(\n",
    "    right_hand_tokens,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    output_path,\n",
    "    max_len=1024,\n",
    "    device=\"cpu\",\n",
    "    valid_token_ids=None,  # ← NEW: pass a list or set of allowed IDs\n",
    "):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    # Ensure right_hand_tokens is a batched tensor\n",
    "    if isinstance(right_hand_tokens, list):\n",
    "        input_ids = torch.tensor([right_hand_tokens], dtype=torch.long, device=device)\n",
    "    elif isinstance(right_hand_tokens, torch.Tensor):\n",
    "        if right_hand_tokens.ndim == 1:\n",
    "            input_ids = right_hand_tokens.unsqueeze(0).to(device)\n",
    "        else:\n",
    "            input_ids = right_hand_tokens.to(device)\n",
    "    else:\n",
    "        raise ValueError(\"right_hand_tokens must be a list of ints or a torch.Tensor\")\n",
    "\n",
    "    bos_token_id = tokenizer.vocab.get(\"BOS_None\", tokenizer.vocab.get(\"BOS\", 0))\n",
    "    eos_token_id = tokenizer.vocab.get(\"EOS_None\", tokenizer.vocab.get(\"EOS\", -1))\n",
    "\n",
    "    decoder_input = torch.tensor([[bos_token_id]], dtype=torch.long, device=device)\n",
    "\n",
    "    #vocab_size = len(tokenizer)\n",
    "    vocab_size = len(valid_token_id_set)\n",
    "\n",
    "    mask_tensor = torch.full((vocab_size,), float('-inf'), device=device)\n",
    "\n",
    "    mask_tensor[valid_token_ids] = 0.0\n",
    "\n",
    "\n",
    "    # Autoregressive generation\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            output = model(input_ids, decoder_input)  # (batch, seq, vocab)\n",
    "            next_token_logits = output[:, -1, :]      # (batch, vocab)\n",
    "\n",
    "            # Apply mask\n",
    "            next_token_logits = next_token_logits + mask_tensor\n",
    "\n",
    "            next_token = torch.argmax(next_token_logits, dim=-1, keepdim=True)\n",
    "            decoder_input = torch.cat([decoder_input, next_token], dim=1)\n",
    "\n",
    "            if next_token.item() == eos_token_id:\n",
    "                break\n",
    "\n",
    "    left_hand_tokens = decoder_input.squeeze(0).tolist()\n",
    "    left_hand_tokens[0:2] = input_ids.squeeze(0).tolist()[0:2]\n",
    "\n",
    "    # Decode to Score objects\n",
    "    print('right tokens', input_ids.squeeze(0).tolist())\n",
    "    print('left tokens', left_hand_tokens)\n",
    "    \n",
    "\n",
    "    right_score = tokenizer.decode(input_ids.squeeze(0).tolist())\n",
    "    left_score = tokenizer.decode(left_hand_tokens)\n",
    "    \n",
    "    print('right score:', right_score)\n",
    "    print('left score:', left_score)\n",
    "\n",
    "    # Convert to MIDI\n",
    "    right_midi = score_to_midi(right_score)\n",
    "    left_midi = score_to_midi(left_score)\n",
    "\n",
    "    #print(right_midi.instruments[0])\n",
    "\n",
    "\n",
    "    print('left midi', left_midi)\n",
    "    # Create MIDI\n",
    "    # Create new MIDI and combine tracks\n",
    "    midi = MidiFile()\n",
    "\n",
    "    # Append notes from decoded MIDI objects\n",
    "    for track, program, name in zip([right_midi, left_midi], [0, 0], [\"RH-1\", \"LH-1\"]):\n",
    "        inst = Instrument(program=program, is_drum=False, name=name)\n",
    "        # Take notes from the first instrument in the decoded track\n",
    "        decoded_inst = track.instruments[0]\n",
    "        inst.notes.extend(decoded_inst.notes)\n",
    "        midi.instruments.append(inst)\n",
    "\n",
    "    midi.dump(str(output_path))\n",
    "\n",
    "    print(f\"Saved MIDI to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "right tokens [4, 897, 557, 868, 888, 46, 146, 157, 888, 49, 146, 157, 825, 565, 888, 49, 146, 157, 569, 888, 49, 146, 157, 573, 888, 49, 146, 157, 577, 888, 46, 146, 157, 581, 888, 42, 146, 157, 585, 888, 46, 146, 157, 589, 888, 46, 146, 157, 888, 49, 146, 157, 825, 597, 888, 49, 146, 157, 601, 888, 49, 146, 157, 605, 888, 49, 146, 157, 609, 888, 46, 146, 157, 613, 888, 49, 146, 157, 617, 888, 54, 146, 157, 4, 897, 557, 888, 49, 146, 157, 888, 53, 146, 157, 825, 565, 888, 49, 146, 157, 569, 888, 49, 146, 157, 573, 888, 49, 146, 157, 825, 581, 888, 49, 146, 157, 825, 589, 888, 49, 146, 157, 825, 597, 888, 49, 156, 157, 888, 61, 156, 157, 825, 605, 888, 51, 156, 157, 888, 63, 156, 157, 825, 613, 888, 53, 156, 157, 888, 65, 156, 157, 825, 557, 888, 58, 132, 157, 888, 61, 132, 157, 888, 68, 132, 157, 825, 565, 888, 58, 141, 159, 888, 61, 141, 159, 888, 66, 141, 159, 825, 581, 888, 58, 132, 157, 888, 65, 132, 157, 825, 589, 888, 58, 132, 157, 888, 61, 132, 157, 888, 68, 132, 157, 825, 597, 888, 58, 141, 159, 888, 61, 141, 159, 888, 66, 141, 159, 824, 612, 888, 58, 132, 157, 888, 63, 132, 157, 825, 620, 888, 46, 132, 165, 888, 58, 132, 165, 4, 897, 564, 888, 49, 132, 157, 888, 54, 132, 157, 580, 888, 49, 132, 159, 888, 54, 132, 159, 825, 596, 888, 58, 132, 157, 888, 61, 132, 157, 825, 604, 888, 58, 132, 157, 888, 63, 132, 157, 825, 612, 888, 810, 888, 58, 132, 157, 888, 61, 132, 157, 888, 65, 132, 157, 825, 620, 888, 58, 132, 157, 888, 61, 132, 157, 888, 68, 132, 157, 825, 564, 888, 58, 141, 159, 888, 61, 141, 159, 888, 66, 141, 159, 825, 580, 888, 58, 132, 157, 888, 65, 132, 157, 825, 588, 888, 58, 132, 157, 888, 61, 132, 157, 888, 68, 132, 157, 825, 596, 888, 58, 141, 159, 888, 61, 141, 159, 888, 66, 141, 159, 825, 612, 888, 58, 132, 157, 888, 63, 132, 157, 825, 620, 888, 47, 132, 165, 888, 59, 132, 165, 4, 897, 564, 888, 53, 132, 157, 888, 56, 132, 157, 580, 888, 53, 132, 159, 888, 56, 132, 159, 825, 596, 888, 56, 132, 157, 888, 59, 132, 157, 825, 604, 888, 56, 132, 157, 888, 61, 132, 157, 825, 612, 888, 810, 888, 56, 132, 157, 888, 59, 132, 157, 888, 63, 132, 157, 825, 620, 888, 56, 132, 157, 888, 59, 132, 157, 888, 66, 132, 157, 825, 564, 888, 56, 141, 159, 888, 59, 141, 159, 888, 65, 141, 159, 825, 580, 888, 59, 132, 157, 888, 63, 132, 157, 825, 588, 888, 56, 132, 157, 888, 59, 132, 157, 888, 66, 132, 157, 825, 596, 888, 56, 141, 159, 888, 59, 141, 159, 888, 65, 141, 159, 825, 612, 888, 59, 132, 157, 888, 63, 132, 157, 825, 620, 888, 47, 132, 165, 888, 59, 132, 165, 4, 897, 564, 888, 53, 132, 157, 888, 56, 132, 157, 580, 888, 53, 132, 159, 888, 56, 132, 159, 825, 596, 888, 56, 132, 157, 888, 59, 132, 157, 825, 604, 888, 56, 132, 157, 888, 61, 132, 157, 825, 612, 888, 810, 888, 56, 132, 157, 888, 59, 132, 157, 888, 63, 132, 157, 825, 620, 888, 56, 132, 157, 888, 59, 132, 157, 888, 66, 132, 157, 825, 564, 888, 56, 141, 159, 888, 59, 141, 159, 888, 65, 141, 159, 825, 580, 888, 59, 132, 157, 888, 63, 132, 157, 824, 587, 888, 56, 132, 157, 888, 59, 132, 157, 888, 66, 132, 157, 825, 595, 888, 56, 141, 159, 888, 59, 141, 159, 888, 65, 141, 159, 825, 611, 888, 59, 132, 157, 888, 63, 132, 157, 825, 619, 888, 46, 132, 165, 888, 58, 132, 165, 4, 897, 563, 888, 49, 132, 157, 888, 54, 132, 157, 579, 888, 49, 132, 159, 888, 54, 132, 159, 825, 595, 888, 49, 141, 157, 888, 61, 141, 157, 825, 603, 888, 51, 141, 157, 888, 63, 141, 157, 825, 611, 888, 53, 141, 157, 888, 65, 141, 157, 825, 619, 888, 58, 132, 157, 888, 61, 132, 157, 888, 68, 132, 157, 825, 563, 888, 58, 141, 159, 888, 61, 141, 159, 888, 66, 141, 159, 825, 579, 888, 58, 132, 157, 888, 65, 132, 157, 825, 587, 888, 58, 132, 157, 888, 61, 132, 157, 888, 68, 132, 157, 825, 595, 888, 58, 141, 159, 888, 61, 141, 159, 888, 66, 141, 159, 825, 611, 888, 58, 132, 157, 888, 63, 132, 157, 825, 619, 888, 46, 132, 165, 888, 58, 132, 165, 4, 897, 563, 888, 49, 132, 157, 888, 54, 132, 157, 579, 888, 49, 132, 159, 888, 54, 132, 159, 825, 595, 888, 54, 132, 157, 888, 58, 132, 157, 825, 603, 888, 54, 132, 157, 888, 57, 132, 157, 825, 611, 888, 54, 132, 157, 888, 58, 132, 157, 825, 619, 888, 55, 132, 157, 888, 61, 132, 157, 888, 64, 132, 157, 825, 563, 888, 55, 141, 159, 888, 63, 141, 159, 825, 579, 888, 55, 132, 157, 888, 61, 132, 157, 825, 587, 888, 55, 132, 157, 888, 61, 132, 157, 888, 64, 132, 157, 825, 595, 888, 55, 141, 159, 888, 63, 141, 159, 825, 611, 888, 55, 132, 157, 888, 61, 132, 157, 825, 619, 888, 47, 132, 165, 888, 59, 132, 165, 4, 897, 563, 888, 51, 132, 157, 888, 56, 132, 157, 579, 888, 51, 132, 159, 888, 56, 132, 159, 825, 595, 888, 51, 132, 157, 888, 63, 132, 157, 825, 603, 888, 50, 132, 157, 888, 62, 132, 157, 825, 611, 888, 51, 132, 157, 888, 63, 132, 157, 825, 619, 888, 58, 132, 157, 888, 63, 132, 157, 888, 70, 132, 157, 829, 571, 888, 56, 141, 161, 888, 63, 141, 161, 888, 68, 141, 161, 824, 594, 888, 51, 132, 157, 888, 63, 132, 157, 825, 602, 888, 50, 132, 157, 888, 62]\n",
      "left tokens [4, 897, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157, 4, 146, 157]\n",
      "right score: Score(ttype=Tick, tpq=32, begin=0, end=1890, tracks=1, notes=207, time_sig=1, key_sig=0, markers=0)\n",
      "left score: Score(ttype=Tick, tpq=32, begin=0, end=0, tracks=0, notes=0, time_sig=1, key_sig=0, markers=0)\n",
      "left midi ticks per beat: 480\n",
      "max tick: 0\n",
      "tempo changes: 0\n",
      "time sig: 0\n",
      "key sig: 0\n",
      "markers: 0\n",
      "lyrics: False\n",
      "instruments: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Call the generation function\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[43mgenerate_left_hand_and_save_midi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mright_hand_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_hand_sample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgenerated_ragtime.mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_token_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_token_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 86\u001b[0m, in \u001b[0;36mgenerate_left_hand_and_save_midi\u001b[0;34m(right_hand_tokens, model, tokenizer, output_path, max_len, device, valid_token_ids)\u001b[0m\n\u001b[1;32m     84\u001b[0m inst \u001b[38;5;241m=\u001b[39m Instrument(program\u001b[38;5;241m=\u001b[39mprogram, is_drum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Take notes from the first instrument in the decoded track\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m decoded_inst \u001b[38;5;241m=\u001b[39m \u001b[43mtrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstruments\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     87\u001b[0m inst\u001b[38;5;241m.\u001b[39mnotes\u001b[38;5;241m.\u001b[39mextend(decoded_inst\u001b[38;5;241m.\u001b[39mnotes)\n\u001b[1;32m     88\u001b[0m midi\u001b[38;5;241m.\u001b[39minstruments\u001b[38;5;241m.\u001b[39mappend(inst)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(dataloader))\n",
    "\n",
    "\n",
    "right_hand_sample = sample_batch[0][0]  # First sample of the right-hand batch\n",
    "left_hand_sample = sample_batch[1][0] \n",
    "\n",
    "vocab_size = len(tokenizer)\n",
    "vocab_size = len(valid_token_id_set)\n",
    "\n",
    "model = MusicTransformer(vocab_size=vocab_size)\n",
    "model.load_state_dict(torch.load(Path('best_model.pth'), weights_only=True))\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "# Call the generation function\n",
    "generate_left_hand_and_save_midi(\n",
    "    right_hand_tokens=right_hand_sample,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    output_path=\"generated_ragtime.mid\",\n",
    "    device=device,\n",
    "    valid_token_ids=valid_token_ids,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
