{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU (Windows)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Using GPU (Windows)')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print('Using GPU (Mac)')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Using CPU')\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# Load miditok tokenizer\n",
    "from miditok import REMI, TokenizerConfig, TokSequence\n",
    "from miditoolkit import MidiFile, Instrument, Note\n",
    "from miditok.pytorch_data import DatasetJSON\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = REMI.from_pretrained(\"tokenizer.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDITokenDataset(Dataset):\n",
    "    def __init__(self, files_paths, bos_token_id=None, eos_token_id=None, max_seq_len=1024):\n",
    "        self.paths = files_paths\n",
    "        self.bos = bos_token_id\n",
    "        self.eos = eos_token_id\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load list of ids\n",
    "        with open(self.paths[idx], \"r\") as f:\n",
    "            ids = json.load(f)\n",
    "\n",
    "        # Wrap in TokSequence (optional â€” just to stay consistent)\n",
    "        seq = TokSequence(ids=ids)\n",
    "\n",
    "        # Add BOS and EOS if specified\n",
    "        tokens = []\n",
    "        if self.bos is not None:\n",
    "            tokens.append(self.bos)\n",
    "        tokens += seq.ids\n",
    "        if self.eos is not None:\n",
    "            tokens.append(self.eos)\n",
    "\n",
    "        # Truncate or pad as needed\n",
    "        tokens = tokens[:self.max_seq_len]\n",
    "\n",
    "        return torch.tensor(tokens)\n",
    "\n",
    "    \n",
    "# ----- Collate function -----\n",
    "def collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "\n",
    "    pad_token_id = tokenizer[\"PAD_None\"]\n",
    "    input_ids_padded = nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=pad_token_id)\n",
    "    labels_padded = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_padded,\n",
    "        \"labels\": labels_padded,\n",
    "    }\n",
    "class MIDIDataCollator:\n",
    "    def __init__(self, pad_token_id):\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # batch: list of 1D tensors\n",
    "        input_ids_padded = pad_sequence(batch, batch_first=True, padding_value=self.pad_token_id)\n",
    "        labels_padded = input_ids_padded.clone()  # copy for labels\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids_padded,\n",
    "            \"labels\": labels_padded,\n",
    "            \"attention_mask\": (input_ids_padded != self.pad_token_id).long(),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "data_collator = MIDIDataCollator(tokenizer['PAD_None'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_hand_jsons = list(Path(\"tokenized_json/right_hand\").glob(\"*.json\"))\n",
    "\n",
    "dataset = MIDITokenDataset(\n",
    "    files_paths=right_hand_jsons,\n",
    "    bos_token_id = tokenizer[\"BOS\"] if \"BOS\" in tokenizer.special_tokens else tokenizer.vocab[\"BOS_None\"],\n",
    "    eos_token_id = tokenizer[\"EOS\"] if \"EOS\" in tokenizer.special_tokens else tokenizer.vocab[\"EOS_None\"],\n",
    "    max_seq_len=1024\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_positions=1024,\n",
    "    n_layer=6,\n",
    "    n_head=8,\n",
    "    n_embd=512,\n",
    ")\n",
    "model = GPT2LMHeadModel(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10700' max='10700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10700/10700 50:16, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.134100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.318400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.784900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.785400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.724900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.697900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.657400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.628100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.605800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.602700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.569400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.556200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.534900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.529800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.494700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.499600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>1.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.442300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.428800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>1.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.382900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>1.359900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.319600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>1.287700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>1.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.213200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>1.140400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.113700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>1.094400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.099600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>1.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>1.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.980200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.982200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.959200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.937400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.911200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.874800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.867600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.864600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.846900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.828400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.823100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.804400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.776600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.774200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.747800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.742000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.718700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.718500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.683000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.651100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.640700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.633900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.632500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.619600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.607900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.595400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.597400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.577200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.583000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.560500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.557600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.551100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.541400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.523600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.513000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.514600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.507700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.497500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.491100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>0.489100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>0.488500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>0.478800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>0.474700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.474200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10100</td>\n",
       "      <td>0.472200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>0.463800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10300</td>\n",
       "      <td>0.463300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>0.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.464000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.456100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10700</td>\n",
       "      <td>0.455900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=100,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    warmup_steps=100,\n",
    "    logging_dir=\"logs\",\n",
    "    report_to=\"none\",  # or \"tensorboard\" if you use it\n",
    "    save_total_limit=2,\n",
    "    \n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator,\n",
    "    \n",
    ")\n",
    "trainer.train()\n",
    "model.save_pretrained(\"model_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from miditoolkit import MidiFile\n",
    "from miditok import TokSequence\n",
    "\n",
    "# Prepare the mask outside the function (keep this as is)\n",
    "valid_token_ids = list(tokenizer.vocab.values())  # get all integer token IDs\n",
    "valid_token_ids_tensor = torch.tensor(valid_token_ids, device=device)\n",
    "\n",
    "vocab_size = model.config.vocab_size  # 15000\n",
    "mask = torch.full((vocab_size,), float('-inf'), device=device)\n",
    "mask[valid_token_ids_tensor] = 0\n",
    "\n",
    "def generate_unconditional_midi(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    output_path=\"generated.mid\",\n",
    "    max_len=512,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    # Get BOS and EOS token ids correctly from tokenizer.vocab dict\n",
    "    bos_token_id = tokenizer.vocab.get(\"BOS_None\", tokenizer.vocab.get(\"BOS\"))\n",
    "    eos_token_id = tokenizer.vocab.get(\"EOS_None\", tokenizer.vocab.get(\"EOS\"))\n",
    "\n",
    "    generated = [bos_token_id]\n",
    "    input_ids = torch.tensor([generated], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            outputs = model(input_ids=input_ids)\n",
    "            logits = outputs.logits[0, -1, :]  # (vocab_size,)\n",
    "\n",
    "            # Apply mask to block invalid tokens\n",
    "            logits = logits + mask\n",
    "\n",
    "            #next_token_id = torch.argmax(logits).item()\n",
    "            top_k = 50\n",
    "            logits = logits + mask  # apply vocab mask\n",
    "            top_logits, top_indices = torch.topk(logits, top_k)\n",
    "            probs = torch.nn.functional.softmax(top_logits, dim=-1)\n",
    "            next_token_id = top_indices[torch.multinomial(probs, num_samples=1)].item()\n",
    "\n",
    "            if next_token_id == eos_token_id:\n",
    "                break\n",
    "\n",
    "            generated.append(next_token_id)\n",
    "            # Update input_ids with newly generated tokens (avoid recreating tensor every time by slicing)\n",
    "            input_ids = torch.tensor([generated], dtype=torch.long, device=device)\n",
    "\n",
    "    print(f\"Generated {len(generated)} tokens.\")\n",
    "    print(\"Tokens:\", generated)\n",
    "    score = tokenizer.decode(generated)  # symusic ScoreTick object\n",
    "    print(\"Score:\",score)\n",
    "    score.dump_midi(output_path)         # save midi directly via symusic method\n",
    "    print(f\"Saved generated MIDI to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 898\n",
      "Model vocab size: 898\n",
      "Unique vocab size: 898\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokenizer vocab size: {len(tokenizer)}\")\n",
    "print(f\"Model vocab size: {model.config.vocab_size}\")\n",
    "print(\"Unique vocab size:\", len(set(tokenizer.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 513 tokens.\n",
      "Tokens: [1, 4, 897, 557, 868, 835, 589, 888, 63, 145, 157, 594, 888, 65, 145, 157, 824, 600, 888, 66, 145, 157, 605, 888, 68, 145, 157, 610, 888, 67, 145, 157, 824, 616, 888, 70, 145, 157, 4, 897, 557, 888, 65, 145, 157, 562, 888, 63, 145, 157, 824, 568, 888, 58, 145, 157, 573, 888, 60, 145, 157, 578, 888, 58, 145, 157, 824, 584, 888, 58, 145, 157, 589, 888, 60, 145, 161, 610, 888, 56, 145, 157, 4, 897, 557, 888, 55, 145, 157, 824, 568, 888, 53, 138, 157, 573, 888, 55, 138, 158, 888, 58, 138, 158, 888, 61, 138, 158, 830, 613, 888, 55, 138, 160, 888, 63, 138, 160, 578, 888, 67, 138, 160, 589, 888, 51, 138, 157, 594, 888, 51, 138, 160, 600, 888, 55, 138, 158, 888, 53, 138, 160, 610, 888, 63, 138, 157, 824, 4, 897, 557, 888, 55, 138, 157, 562, 888, 55, 138, 157, 824, 568, 888, 51, 138, 157, 573, 888, 53, 138, 157, 824, 584, 888, 57, 138, 157, 589, 888, 55, 138, 157, 594, 888, 58, 138, 157, 824, 600, 888, 53, 138, 157, 605, 888, 55, 138, 157, 610, 888, 53, 138, 157, 824, 616, 888, 55, 138, 157, 4, 897, 557, 888, 55, 138, 157, 562, 888, 55, 138, 157, 824, 568, 888, 51, 138, 157, 573, 888, 51, 138, 157, 578, 888, 53, 138, 157, 824, 584, 888, 51, 138, 157, 589, 888, 51, 138, 157, 594, 888, 55, 138, 157, 824, 600, 888, 55, 138, 157, 605, 888, 53, 138, 157, 610, 888, 55, 138, 157, 824, 616, 888, 53, 138, 157, 4, 897, 557, 888, 51, 138, 157, 562, 888, 56, 138, 157, 824, 568, 888, 51, 138, 157, 573, 888, 53, 139, 157, 578, 888, 55, 139, 157, 824, 584, 888, 50, 139, 157, 589, 888, 62, 139, 157, 594, 888, 56, 140, 157, 824, 600, 888, 55, 141, 157, 605, 888, 62, 141, 157, 610, 888, 56, 141, 158, 824, 4, 897, 557, 888, 60, 142, 157, 888, 51, 144, 157, 562, 888, 56, 145, 158, 824, 568, 888, 63, 145, 158, 888, 60, 145, 158, 824, 578, 888, 48, 138, 157, 824, 584, 888, 53, 138, 157, 589, 888, 51, 138, 157, 594, 888, 55, 138, 157, 605, 888, 50, 138, 157, 610, 888, 55, 138, 157, 824, 616, 888, 53, 138, 157, 4, 897, 557, 888, 51, 138, 157, 562, 888, 50, 138, 157, 824, 568, 888, 55, 138, 157, 573, 888, 53, 138, 157, 578, 888, 51, 138, 157, 824, 584, 888, 51, 138, 157, 589, 888, 53, 138, 157, 594, 888, 55, 138, 157, 824, 600, 888, 51, 138, 157, 605, 888, 53, 138, 157, 610, 888, 55, 138, 157, 824, 616, 888, 55, 138, 157, 4, 897, 557, 888, 51, 138, 158, 824, 568, 888, 53, 138, 157, 573, 888, 51, 138, 157, 578, 888, 51, 138, 157, 589, 888, 53, 138, 158, 824, 600, 888, 55, 138, 158, 824, 610, 888, 51, 138, 158, 888, 57, 138, 158, 824, 4, 897]\n",
      "Score: Score(ttype=Tick, tpq=32, begin=0, end=1274, tracks=1, notes=93, time_sig=1, key_sig=0, markers=0)\n",
      "Saved generated MIDI to unconditional_generation.mid\n"
     ]
    }
   ],
   "source": [
    "# Load trained model if not in memory already\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"out\")  # if needed\n",
    "model = GPT2LMHeadModel.from_pretrained(\"model_weights\").to(device)\n",
    "tokenizer = REMI.from_pretrained(\"tokenizer.json\")\n",
    "\n",
    "generate_unconditional_midi(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    output_path=\"unconditional_generation.mid\",\n",
    "    max_len=512,\n",
    "    device=device\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
