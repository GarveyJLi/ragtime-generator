{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU (Windows)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('Using GPU (Windows)')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print('Using GPU (Mac)')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('Using CPU')\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Config\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "from typing import List\n",
    "\n",
    "# Load miditok tokenizer\n",
    "from miditok import REMI, TokenizerConfig, TokSequence\n",
    "from miditoolkit import MidiFile, Instrument, Note\n",
    "from miditok.pytorch_data import DatasetJSON\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\garve\\anaconda3\\envs\\dsc\\Lib\\site-packages\\miditok\\tokenizations\\remi.py:88: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = REMI.from_pretrained(\"tokenizer.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDITokenDataset(Dataset):\n",
    "    def __init__(self, files_paths, bos_token_id=None, eos_token_id=None, max_seq_len=1024):\n",
    "        self.paths = files_paths\n",
    "        self.bos = bos_token_id\n",
    "        self.eos = eos_token_id\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load list of ids\n",
    "        with open(self.paths[idx], \"r\") as f:\n",
    "            ids = json.load(f)\n",
    "\n",
    "        # Wrap in TokSequence (optional â€” just to stay consistent)\n",
    "        seq = TokSequence(ids=ids)\n",
    "\n",
    "        # Add BOS and EOS if specified\n",
    "        tokens = []\n",
    "        if self.bos is not None:\n",
    "            tokens.append(self.bos)\n",
    "        tokens += seq.ids\n",
    "        if self.eos is not None:\n",
    "            tokens.append(self.eos)\n",
    "\n",
    "        # Truncate or pad as needed\n",
    "        tokens = tokens[:self.max_seq_len]\n",
    "\n",
    "        return torch.tensor(tokens)\n",
    "\n",
    "    \n",
    "# ----- Collate function -----\n",
    "def collate_fn(batch):\n",
    "    input_ids = [item[\"input_ids\"] for item in batch]\n",
    "    labels = [item[\"labels\"] for item in batch]\n",
    "\n",
    "    pad_token_id = tokenizer[\"PAD_None\"]\n",
    "    input_ids_padded = nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=pad_token_id)\n",
    "    labels_padded = nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids_padded,\n",
    "        \"labels\": labels_padded,\n",
    "    }\n",
    "class MIDIDataCollator:\n",
    "    def __init__(self, pad_token_id):\n",
    "        self.pad_token_id = pad_token_id\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # batch: list of 1D tensors\n",
    "        input_ids_padded = pad_sequence(batch, batch_first=True, padding_value=self.pad_token_id)\n",
    "        labels_padded = input_ids_padded.clone()  # copy for labels\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": input_ids_padded,\n",
    "            \"labels\": labels_padded,\n",
    "            \"attention_mask\": (input_ids_padded != self.pad_token_id).long(),\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "data_collator = MIDIDataCollator(tokenizer['PAD_None'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_hand_jsons = list(Path(\"tokenized_json/right_hand\").glob(\"*.json\"))\n",
    "\n",
    "dataset = MIDITokenDataset(\n",
    "    files_paths=right_hand_jsons,\n",
    "    bos_token_id = tokenizer[\"BOS\"] if \"BOS\" in tokenizer.special_tokens else tokenizer.vocab[\"BOS_None\"],\n",
    "    eos_token_id = tokenizer[\"EOS\"] if \"EOS\" in tokenizer.special_tokens else tokenizer.vocab[\"EOS_None\"],\n",
    "    max_seq_len=512*2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_positions=1024,\n",
    "    n_layer=6,\n",
    "    n_head=8,\n",
    "    n_embd=512,\n",
    ")\n",
    "model = GPT2LMHeadModel(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='305' max='107000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   305/107000 02:51 < 16:48:41, 1.76 it/s, Epoch 2.84/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.174700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.305300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.015500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     15\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \n\u001b[0;32m     19\u001b[0m )\n\u001b[1;32m---> 20\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\garve\\anaconda3\\envs\\dsc\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\garve\\anaconda3\\envs\\dsc\\Lib\\site-packages\\transformers\\trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2548\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2549\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2553\u001b[0m )\n\u001b[0;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2561\u001b[0m ):\n\u001b[0;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\garve\\anaconda3\\envs\\dsc\\Lib\\site-packages\\transformers\\trainer.py:3791\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   3789\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 3791\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3793\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\garve\\anaconda3\\envs\\dsc\\Lib\\site-packages\\accelerate\\accelerator.py:2473\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2471\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2472\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2473\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\garve\\anaconda3\\envs\\dsc\\Lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\garve\\anaconda3\\envs\\dsc\\Lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\garve\\anaconda3\\envs\\dsc\\Lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=1000,\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    warmup_steps=100,\n",
    "    logging_dir=\"logs\",\n",
    "    report_to=\"none\",  # or \"tensorboard\" if you use it\n",
    "    save_total_limit=2,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=data_collator,\n",
    "    \n",
    ")\n",
    "trainer.train()\n",
    "model.save_pretrained(\"model_weights\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from miditoolkit import MidiFile\n",
    "from miditok import TokSequence\n",
    "\n",
    "# Prepare the mask outside the function (keep this as is)\n",
    "valid_token_ids = list(tokenizer.vocab.values())  # get all integer token IDs\n",
    "valid_token_ids_tensor = torch.tensor(valid_token_ids, device=device)\n",
    "\n",
    "vocab_size = model.config.vocab_size  # 15000\n",
    "mask = torch.full((vocab_size,), float('-inf'), device=device)\n",
    "mask[valid_token_ids_tensor] = 0\n",
    "\n",
    "def generate_unconditional_midi(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    output_path=\"generated.mid\",\n",
    "    max_len=512*2,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    # Get BOS and EOS token ids correctly from tokenizer.vocab dict\n",
    "    bos_token_id = tokenizer.vocab.get(\"BOS_None\", tokenizer.vocab.get(\"BOS\"))\n",
    "    eos_token_id = tokenizer.vocab.get(\"EOS_None\", tokenizer.vocab.get(\"EOS\"))\n",
    "\n",
    "    generated = [bos_token_id]\n",
    "    input_ids = torch.tensor([generated], dtype=torch.long, device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            outputs = model(input_ids=input_ids)\n",
    "            logits = outputs.logits[0, -1, :]  # (vocab_size,)\n",
    "\n",
    "            # Apply mask to block invalid tokens\n",
    "            logits = logits + mask\n",
    "\n",
    "            #next_token_id = torch.argmax(logits).item()\n",
    "            top_k = 50\n",
    "            logits = logits + mask  # apply vocab mask\n",
    "            top_logits, top_indices = torch.topk(logits, top_k)\n",
    "            probs = torch.nn.functional.softmax(top_logits, dim=-1)\n",
    "            next_token_id = top_indices[torch.multinomial(probs, num_samples=1)].item()\n",
    "\n",
    "            if next_token_id == eos_token_id:\n",
    "                break\n",
    "\n",
    "            generated.append(next_token_id)\n",
    "            # Update input_ids with newly generated tokens (avoid recreating tensor every time by slicing)\n",
    "            input_ids = torch.tensor([generated], dtype=torch.long, device=device)\n",
    "\n",
    "    print(f\"Generated {len(generated)} tokens.\")\n",
    "    print(\"Tokens:\", generated)\n",
    "    score = tokenizer.decode(generated)  # symusic ScoreTick object\n",
    "    print(\"Score:\",score)\n",
    "    score.dump_midi(output_path)         # save midi directly via symusic method\n",
    "    print(f\"Saved generated MIDI to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocab size: 898\n",
      "Model vocab size: 898\n",
      "Unique vocab size: 898\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokenizer vocab size: {len(tokenizer)}\")\n",
    "print(f\"Model vocab size: {model.config.vocab_size}\")\n",
    "print(\"Unique vocab size:\", len(set(tokenizer.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1025 tokens.\n",
      "Tokens: [1, 4, 897, 557, 868, 888, 60, 153, 157, 888, 63, 153, 157, 888, 70, 153, 157, 562, 888, 68, 145, 157, 567, 888, 60, 145, 157, 572, 888, 48, 153, 158, 888, 51, 153, 158, 888, 58, 153, 158, 824, 583, 888, 56, 145, 157, 588, 888, 51, 145, 158, 824, 598, 888, 50, 145, 157, 888, 55, 145, 157, 824, 604, 888, 50, 145, 158, 888, 53, 145, 158, 824, 614, 888, 49, 145, 158, 888, 51, 145, 158, 824, 560, 888, 50, 145, 157, 565, 888, 49, 145, 157, 888, 51, 145, 157, 824, 571, 888, 53, 145, 157, 576, 888, 50, 153, 158, 888, 55, 153, 158, 824, 586, 888, 50, 153, 158, 888, 53, 153, 158, 824, 596, 888, 50, 153, 157, 888, 55, 153, 157, 824, 602, 888, 50, 153, 159, 888, 53, 153, 159, 824, 617, 888, 49, 153, 158, 888, 51, 153, 158, 829, 574, 888, 39, 156, 158, 888, 51, 156, 158, 829, 595, 888, 60, 145, 157, 888, 63, 145, 157, 888, 70, 145, 157, 600, 888, 68, 138, 157, 605, 888, 60, 138, 157, 610, 888, 48, 145, 158, 888, 51, 145, 158, 888, 58, 145, 158, 824, 620, 888, 56, 138, 157, 824, 562, 888, 51, 138, 158, 824, 572, 888, 60, 145, 157, 888, 63, 145, 157, 888, 70, 145, 157, 577, 888, 68, 138, 157, 582, 888, 60, 138, 157, 587, 888, 48, 145, 158, 888, 51, 145, 158, 888, 58, 145, 158, 824, 598, 888, 56, 138, 157, 603, 888, 51, 138, 158, 824, 613, 888, 58, 145, 157, 888, 61, 145, 157, 888, 67, 145, 157, 618, 888, 65, 138, 157, 824, 560, 888, 61, 138, 157, 565, 888, 58, 138, 158, 824, 575, 888, 53, 138, 157, 580, 888, 49, 138, 157, 585, 888, 46, 138, 157, 824, 591, 888, 41, 138, 162, 616, 888, 52, 138, 157, 824, 558, 888, 53, 138, 157, 563, 888, 54, 138, 157, 568, 888, 55, 138, 158, 824, 578, 888, 55, 138, 158, 888, 58, 138, 158, 824, 589, 888, 55, 138, 158, 888, 61, 138, 158, 824, 599, 888, 55, 138, 158, 888, 61, 138, 158, 888, 67, 138, 158, 824, 609, 888, 55, 138, 157, 888, 61, 138, 157, 888, 65, 138, 157, 824, 615, 888, 55, 138, 157, 888, 61, 138, 157, 888, 67, 138, 157, 620, 888, 55, 138, 157, 888, 61, 138, 157, 888, 63, 138, 157, 4, 897, 561, 888, 55, 138, 158, 888, 61, 138, 158, 888, 65, 138, 158, 824, 571, 888, 63, 138, 157, 576, 888, 61, 138, 157, 824, 582, 888, 58, 138, 157, 587, 888, 56, 138, 158, 824, 597, 888, 56, 138, 158, 888, 60, 138, 158, 824, 607, 888, 56, 138, 158, 888, 63, 138, 158, 824, 618, 888, 56, 138, 158, 888, 62, 138, 158, 888, 67, 138, 158, 824, 564, 888, 55, 138, 157, 888, 61, 138, 157, 888, 65, 138, 157, 569, 888, 55, 138, 157, 888, 61, 138, 157, 888, 67, 138, 157, 574, 888, 55, 138, 157, 888, 61, 138, 157, 888, 63, 138, 157, 824, 580, 888, 55, 138, 159, 888, 61, 138, 159, 888, 65, 138, 159, 824, 595, 888, 55, 138, 158, 888, 61, 138, 158, 888, 63, 138, 158, 824, 606, 888, 60, 145, 157, 888, 63, 145, 157, 888, 70, 145, 157, 611, 888, 68, 138, 157, 616, 888, 60, 138, 157, 4, 897, 557, 888, 48, 145, 158, 888, 51, 145, 158, 888, 58, 145, 158, 824, 567, 888, 56, 138, 157, 824, 573, 888, 51, 138, 158, 824, 583, 888, 60, 145, 157, 888, 63, 145, 157, 888, 70, 145, 157, 588, 888, 68, 138, 157, 593, 888, 60, 138, 157, 598, 888, 48, 145, 158, 888, 51, 145, 158, 888, 58, 145, 158, 824, 609, 888, 56, 138, 157, 614, 888, 51, 138, 158, 824, 560, 888, 58, 145, 157, 888, 61, 145, 157, 888, 67, 145, 157, 565, 888, 65, 138, 157, 824, 571, 888, 61, 138, 157, 576, 888, 58, 138, 158, 824, 586, 888, 53, 138, 157, 591, 888, 49, 138, 157, 596, 888, 46, 138, 157, 824, 602, 888, 41, 138, 162, 4, 897, 563, 888, 52, 138, 157, 824, 569, 888, 53, 138, 157, 574, 888, 54, 138, 157, 579, 888, 55, 138, 158, 824, 589, 888, 55, 138, 158, 888, 58, 138, 158, 824, 600, 888, 55, 138, 158, 888, 61, 138, 158, 824, 610, 888, 55, 138, 158, 888, 61, 138, 158, 888, 67, 138, 158, 824, 620, 888, 55, 138, 157, 888, 61, 138, 157, 888, 65, 138, 157, 824, 562, 888, 55, 138, 157, 888, 61, 138, 157, 888, 67, 138, 157, 567, 888, 55, 138, 157, 888, 61, 138, 157, 888, 63, 138, 157, 572, 888, 55, 138, 158, 888, 61, 138, 158, 888, 65, 138, 158, 824, 582, 888, 55, 138, 157, 888, 61, 138, 157, 888, 63, 138, 157, 587, 888, 55, 138, 158, 888, 61, 138, 158, 888, 65, 138, 158, 824, 598, 888, 56, 138, 157, 888, 60, 138, 157, 888, 68, 138, 157, 603, 888, 56, 138, 157, 888, 63, 138, 157, 608, 888, 56, 138, 157, 888, 64, 138, 157, 613, 888, 56, 145, 158, 888, 65, 145, 158, 824, 560, 888, 55, 138, 157, 888, 63, 138, 157, 565, 888, 55, 138, 158, 888, 60, 138, 158, 824, 575, 888, 56, 138, 158, 824, 585, 888, 52, 145, 158, 888, 56, 145, 158, 888, 62, 145, 158, 888, 64, 145, 158, 824, 596, 888, 53, 145, 158, 888, 56, 145, 158, 888, 61, 145, 158, 888, 65, 145, 158, 824, 606, 888, 55, 145, 158, 888, 58, 145, 158, 888, 61, 145, 158, 888, 67, 145, 158, 824, 616, 888, 60, 153, 157, 888, 63, 153, 157, 888, 70, 153, 157, 824, 558, 888, 68, 145, 157, 563, 888, 60, 145, 157, 568, 888, 48, 153, 158, 888, 51, 153, 158, 888, 58, 153, 158, 824, 578, 888, 56, 145, 157, 824, 584, 888, 51, 145, 158, 824, 594, 888, 60, 153, 157, 888, 63, 153, 157, 888, 70, 153, 157, 599, 888, 68, 145, 157, 604, 888]\n",
      "Score: Score(ttype=Tick, tpq=32, begin=0, end=1756, tracks=1, notes=210, time_sig=1, key_sig=0, markers=0)\n",
      "Saved generated MIDI to unconditional_generation.mid\n"
     ]
    }
   ],
   "source": [
    "# Load trained model if not in memory already\n",
    "# model = GPT2LMHeadModel.from_pretrained(\"out\")  # if needed\n",
    "model = GPT2LMHeadModel.from_pretrained(\"model_weights\").to(device)\n",
    "tokenizer = REMI.from_pretrained(\"tokenizer.json\")\n",
    "\n",
    "generate_unconditional_midi(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    output_path=\"unconditional_generation.mid\",\n",
    "    max_len=512*2,\n",
    "    device=device\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
